

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Using PyNFG to find level k equilibria &mdash; PyNFG 0.1 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="PyNFG 0.1 documentation" href="index.html" />
    <link rel="next" title="Best Response" href="pynfg.bestresponse.html" />
    <link rel="prev" title="Utilities" href="pynfg.utilities.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pynfg.bestresponse.html" title="Best Response"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="pynfg.utilities.html" title="Utilities"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">PyNFG 0.1 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="using-pynfg-to-find-level-k-equilibria">
<span id="levelksolutions"></span><h1>Using PyNFG to find level k equilibria<a class="headerlink" href="#using-pynfg-to-find-level-k-equilibria" title="Permalink to this headline">¶</a></h1>
<p>The level K solution concept is an alternative to the traditional Nash Equilibrium.  In such a framework, each player is assumed to be a certain integer level.  A player of level k models all other players as level k-1, while the level 0 distribution for each player is assumed to be common knowledge and is prespecified before the start of the game.  A level k equilibrium is where each player maximizes her expected utility at level k, assuming all other players are level k-1.</p>
<p>The quickest way to grasp the framework of PyNFG is to work through the extended example below.
Although the example is based around the relaxed level k equilibrium in which player&#8217;s rationality is bounded by the number of strategies they can choose from, the general structure of how to use the solvers is the same for traditional level k equilibrium.</p>
<div class="section" id="extended-example">
<h2>Extended Example<a class="headerlink" href="#extended-example" title="Permalink to this headline">¶</a></h2>
<div class="section" id="solving-a-static-game">
<h3>Solving a static game<a class="headerlink" href="#solving-a-static-game" title="Permalink to this headline">¶</a></h3>
<p>Suppose we are interested in using relaxed level k to estimate the strategies of the players in the Stackelberg game.  Let G be the SemiNFG created in the Stackelberg game included in this package.  First, we have to specify a number of parameters for each player.  In the relaxed level k scenario, the parameters are M, Mprime, the satisficing distribution the level and the level 0 distribution of all players.  The format is to specify the parameters in a triply-nested dictionary where the outer layer keys are player names.  In the dictionary for each player, there are keys for parameters that do not depend on the specific node of the player.  In this case, the only parameter in the player&#8217;s dictionary is the level.  The rest of the keys in the player&#8217;s dictionary are node names. For each node, keys are M, Mprime, SDist, L0Dist.  However, the rlk_dict function creates the shell for this dictionary so the end user can just modify keys.</p>
<div class="highlight-ipython"><pre>In [1]: player_info = rlk_dict(G, M=10, Mprime=10, Level=2, SDist =   'all pure', L0Dist = 'uniform')
In [2]: player_info
Out[2]:
     {'1': {'Q1': {'L0Dist': 'uniform',
     'M': 10,
     'Mprime': 10,
     'SDist': 'all pure'}, 'Level': 2},
     '2': {'Q2': {'L0Dist': 'uniform',
     'M': 10,
     'Mprime': 10,
     'SDist': 'all pure'}, 'Level': 2,}}</pre>
</div>
<p>The inputs to rlk_dict are set for all players.  However, modifying the dictionary is simple.  For example, we can set</p>
<div class="highlight-ipython"><pre>In [3]: player_info['2']['Level']=3
In [4]: player_info
Out[4]:
     {'1': {'Q1': {'L0Dist': 'uniform',
     'M': 10,
     'Mprime': 10,
     'SDist': 'all pure'}, 'Level': 2},
     '2': {'Q2': {'L0Dist': 'uniform',
     'M': 10,
     'Mprime': 10,
     'SDist': 'all pure'}, 'Level': 3,}}</pre>
</div>
<p>Now that the details of the game are specified, it is possible to solve the game.  To do this, just create an rlk instance and call method solve_game()</p>
<div class="highlight-ipython"><pre>In [5]: solver = RLK(G,player_info, 10)
In [6]: solver.solve_game()
Training Q1 at level 1
Training Q2 at level 1
Training Q1 at level 2
Training Q2 at level 2
Training Q2 at level 3</pre>
</div>
<p>To see the solved CPT for a player, access the rlk&#8217;s instance of the game (not the original inputted game.  Then select a decision node and view its new attribute LevelCPT</p>
<div class="highlight-ipython"><pre>In [7]: solver.G.node_dict['Q1'].LevelCPT
Out[7]: {'Level0': array([[ 0.16666667,  0.16666667,  0.16666667,  0.16666667,  0.16666667, 0.16666667], [ 0.16666667,  0.16666667,  0.16666667,  0.16666667,  0.16666667, 0.16666667], [ 0.16666667,  0.16666667,  0.16666667,  0.16666667,  0.16666667,0.16666667]]), 'Level1': array([[ 0. ,  0. ,  0. ,  0.5,  0.4,  0.1], [ 0. ,  0. ,  0.3,  0.4,  0.3,  0. ], [ 0. ,  0. ,  0.8,  0.1,  0.1,  0. ]]), 'Level2': array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.43333333, 0.56666667], [ 0.        ,  0.        ,  0.        ,  0.26666667,  0.5       , 0.23333333], [ 0.        ,  0.3       ,  0.7       ,  0.        ,  0.        , 0.        ]])}</pre>
</div>
<p>The result is a dictionary consisting of the player&#8217;s strategies for each level trained.  Note that even if a player is level 1, LevelCPT might also contain a level 2 strategy if other players are level 3 or greater.</p>
<p>To train player 1 to level three without resolving the entire game, just do</p>
<div class="highlight-ipython"><pre>In [8]: solver.train_node('Q1',3)
Training Q1 at level 3</pre>
</div>
<p>Now calling <strong>solver.G.node_dict[&#8216;Q1&#8217;]</strong> will have an entry for Level 3.</p>
<p>Now, to find the level k best response solution, follow the same steps but use the BestResponse solver and br_dict to specify the parameters</p>
<div class="highlight-ipython"><pre>In [9]: player_info_br = br_dict(G, 10, 2, L0Dist = 'uniform', beta=2)
In [10]: BRsolver = BestResponse(G, player_info_br)
In [11]: BRSolver.solve_game(logit=True)
Training Q1 at level 1
Training Q2 at level 1
Training Q1 at level 2
Training Q2 at level 2
In [12]: BRSolver.train_node('Q1',3)
Training Q1 at level 3</pre>
</div>
<p>Note that by specifying a beta parameter and logit=True, best response is actually calculating the quantal response which converges to the best response as beta approaches infinity.</p>
</div>
<div class="section" id="solving-iterated-games">
<h3>Solving Iterated Games<a class="headerlink" href="#solving-iterated-games" title="Permalink to this headline">¶</a></h3>
<p>In the simplest fashion, iterated games are solved the same way as non-iterated games.  However, there are a few minor differences that will be discussed below.</p>
<p>Now assume that G is the hide and seek game included in this package.  Suppose we want to solve it using Monte Carlo Reinforcement Learning (MCRL).</p>
<div class="highlight-ipython"><pre>In [13]: player_info_mcrl=mcrl_dict(G, 2, 10, 10,1, L0Dist='uniform')
In [14]: solverMCRL = EWMA_MCRL(G, player_info_mcrl)
In [15]: solverMCRL.solve_game()
Training Dseek at level 1
0
1
2
3
4
5
6
7
8
9
Training Dhide at level 1
0
1
2
3
4
5
6
7
8
9
Training Dseek at level 2
0
1
2
3
4
5
6
7
8
9
Training Dhide at level 2
0
1
2
3
4
5
6
7
8
9</pre>
</div>
<p>However, instead of the solved CPTs being attached to a node, the trained CPTs are stored as an attribute of the solver instance.</p>
<div class="highlight-ipython"><pre>In [17]: solverMCRL.trained_CPTs</pre>
</div>
<p>will return a d triply nested dictionary.  The first layer of keys are players, the second layer of keys are base names and the third layer specifies the level.  For example</p>
<div class="highlight-ipython"><pre>In [18]: solverMCRL.trained_CPTs['hider']['Dhide']['Level1']</pre>
</div>
<p>gives the level 1 CPT for the hiders Dhide basename.  Also there are figures that indicate convergence of the solver.  They are stored as an attribute of the solver class.  It is a nested dictionary where the first layer of keys are basenames and the second layer are level numbers.</p>
<div class="highlight-ipython"><pre>In [19]: solverMCRL.figs
Out[19]:
{'Dhide': {'1': &lt;matplotlib.figure.Figure at 0x424d410&gt;,
'2': &lt;matplotlib.figure.Figure at 0x4cf9a10&gt;},
'Dseek': {'1': &lt;matplotlib.figure.Figure at 0x3fa81d0&gt;,
'2': &lt;matplotlib.figure.Figure at 0x49ef8d0&gt;}}</pre>
</div>
</div>
<div class="section" id="solving-for-a-node-in-an-iterated-game">
<h3>Solving for a node in an iterated game<a class="headerlink" href="#solving-for-a-node-in-an-iterated-game" title="Permalink to this headline">¶</a></h3>
<p>Calling solverMCRL.solve_game() and solverMCRL.train_node(.) finds an optimal policy for the basenames.  Sometimes, a user might want to find a best response for a specific node of a basename given the current values of the CPTs for all other players.  To accomplish this, just use BestResponse</p>
<div class="highlight-ipython"><pre>In [20]: player_info_br = br_dict(G, 30, 2)
In [21]: BRsolver = BestResponse(G, player_info_br)
/usr/local/bin/ipython:109: UserWarning: No entry for L0Dist for player seeker,                        setting to current CPT
/usr/local/bin/ipython:109: UserWarning: No entry for L0Dist for player hider,                        setting to current CPT
In [22]: BRSolver.train_node('Dseek2',1)
Training Dseek2 at level 1</pre>
</div>
<p>To see the new CPT just do</p>
<div class="highlight-ipython"><pre>In [23]: seek2CPT = BRSolver.G.node_dict['Dseek2'].LevelCPT['Level1']</pre>
</div>
</div>
</div>
<div class="section" id="solvers">
<h2>Solvers<a class="headerlink" href="#solvers" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="pynfg.bestresponse.html">Best Response</a></li>
<li class="toctree-l1"><a class="reference internal" href="pynfg.rlk.html">Relaxed Level K</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pynfg.rlk.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynfg.rlk.html#rlk-in-parallel">RLK in parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="pynfg.rlk.html#module-pynfg.levelksolutions.rlk">Detailed Documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pynfg.mcrl.html">MCRL</a></li>
<li class="toctree-l1"><a class="reference internal" href="pynfg.qlearning.html">Q Learning</a></li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Using PyNFG to find level k equilibria</a><ul>
<li><a class="reference internal" href="#extended-example">Extended Example</a><ul>
<li><a class="reference internal" href="#solving-a-static-game">Solving a static game</a></li>
<li><a class="reference internal" href="#solving-iterated-games">Solving Iterated Games</a></li>
<li><a class="reference internal" href="#solving-for-a-node-in-an-iterated-game">Solving for a node in an iterated game</a></li>
</ul>
</li>
<li><a class="reference internal" href="#solvers">Solvers</a><ul>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="pynfg.utilities.html"
                        title="previous chapter">Utilities</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pynfg.bestresponse.html"
                        title="next chapter">Best Response</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/pynfg.levelksolutions.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pynfg.bestresponse.html" title="Best Response"
             >next</a> |</li>
        <li class="right" >
          <a href="pynfg.utilities.html" title="Utilities"
             >previous</a> |</li>
        <li><a href="index.html">PyNFG 0.1 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, James Bono.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>